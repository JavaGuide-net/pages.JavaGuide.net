import{_ as a,o as s,h as e,Q as l}from"./chunks/framework.da611722.js";const o="/assets/JavaGuide_Kafka_通信3_segment_分成三段.ce54311b.png",n="/assets/JavaGuide_Kafka_通信3_segment里边_index_log的对应关系.4ee48851.png",p="/assets/JavaGuide_Kafka_通信3_日志压缩策略.6b848825.png",t="/assets/JavaGuide_Kafka_通信3_一个Topic_三个分区_三个副本.67294a94.png",r="/assets/JavaGuide_Kafka_通信3_一个Topic_三个分区_三个副本_leader_follower.f48f3cee.png",c="/assets/JavaGuide_Kafka_通信3_副本协同机制.484e95f4.png",i="/assets/JavaGuide_Kafka_通信3_Leader_Follower初始状态.cc71c53e.png",d="/assets/JavaGuide_Kafka_通信3_生产者发送一条消息.ce8228d5.png",y="/assets/JavaGuide_Kafka_通信3_Follower_Fetch消息.3a5de3e1.png",E="/assets/JavaGuide_Kafka_通信3_Follower_副本收到消息.6001baf7.png",f="/assets/JavaGuide_Kafka_通信3_数据更新完成.dcef8a1a.png",u="/assets/JavaGuide_Kafka_通信3_数据丢失问题.d57e22dc.png",h="/assets/JavaGuide_Kafka_通信3_数据丢失问题解决方案.63c41ed9.png",m="/assets/JavaGuide_Kafka_通信3_Kafka发送数据.8b976fdf.png",D=JSON.parse('{"title":"分布式消息通信Kafka(三) | Java面试指南","description":"","frontmatter":{"head":[["link",{"rel":"canonical","href":"https://javaguide.net/百万架构师/kafka/分布式消息通信Kafka(三).html"}],["meta",{"name":"keywords","content":"分布式消息通信Kafka(三) | Java面试指南 | JavaGuide | Java面试指南 | NoGeek ｜不止极客Java基础, 多线程, JVM, 虚拟机, 数据库, MySQL, Spring, Redis, MyBatis, 系统设计, 分布式, RPC, 高可用, 高并发"}],["meta",{"name":"og:url","content":"https://JavaGuide.net"}],["meta",{"name":"og:type","content":"website"}],["meta",{"name":"og:image","content":"https://javaguide.net/JavaGuide-og.png"}],["meta",{"name":"og:title","content":"分布式消息通信Kafka(三) | Java面试指南 | JavaGuide | Java面试指南 | NoGeek ｜不止极客"}],["meta",{"name":"og:description","content":"分布式消息通信Kafka(三) | Java面试指南 | JavaGuide | Java面试指南 | NoGeek ｜不止极客 | 「JavaGuide.net」一份涵盖大部分 Java 程序员所需要掌握的核心知识。准备 Java 面试，首选 JavaGuide.net ！"}],["meta",{"name":"twitter:site","content":"https://javaguide.net"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:creator","content":"nogeek.cn"}],["meta",{"name":"twitter:title","content":"分布式消息通信Kafka(三) | Java面试指南 | JavaGuide | Java面试指南 | NoGeek ｜不止极客"}],["meta",{"name":"twitter:description","content":"分布式消息通信Kafka(三) | Java面试指南 | JavaGuide | Java面试指南 | NoGeek ｜不止极客 | 「JavaGuide.net」一份涵盖大部分 Java 程序员所需要掌握的核心知识。准备 Java 面试，首选 JavaGuide.net ！"}],["meta",{"name":"twitter:image","content":"https://javaguide.net/JavaGuide-og.png"}],["meta",{"name":"baidu-site-verification","content":"codeva-MXEPYsXKGk"}],["meta",{"name":"msvalidate.01","content":"9F2D57CFC59E8031212A166878638B15"}]]},"headers":[],"relativePath":"百万架构师/kafka/分布式消息通信Kafka(三).md","filePath":"百万架构师/kafka/分布式消息通信Kafka(三).md","lastUpdated":1740370683000}'),g={name:"百万架构师/kafka/分布式消息通信Kafka(三).md"},k=l(`<h3 id="课程目标" tabindex="-1">课程目标 <a class="header-anchor" href="#课程目标" aria-label="Permalink to &quot;课程目标&quot;">​</a></h3><ol><li><p>消息的存储原理</p></li><li><p>Partition 的副本机制原理</p></li><li><p>副本数据的同步原理</p></li></ol><p>​ 消息的发送策略，根据 key 的算法路由到 Kafka 的一个分区上，分区是一个物理上的一个结构。Linux 会定时清理 <code>/tmp</code> 目录下的文件。生产环境的时候，文件都是另外放到另一个磁盘上。server 里边可以配置日志文件的路径。具体的分区会落到我们磁盘的某一个路径下，分区可以指定我们这个 Topic 分成多少个分区。分区可以指定对于当前这个 <code>Topic</code> 分成多少个分区。</p><p>​ 分区落到我们的 <code>broker</code> 上的位置。消费者去消费指定分区，还可以根据 Kafka 的消息路由策略消费：随机或范围。当我们消费端出现变化，Topic 取消订阅的时候，会触发 ConsumerReblance 的机制，叫做重新负载均衡。我们会选择一个 <strong>coordinator</strong> 这样一个角色，组建一个 Consumer group ，形成这样一个消息分发的一个策略。在 Consumer 里边去选择一个 Consumer Leader 。Leader 通过 range 策略，去决定哪一个消费者消费哪一个分区，这就是一个消费端的负载均衡策略。最好每个消费端消费一个分区，设置太多是没有价值的。</p><h1 id="消息的文件存储机制" tabindex="-1">消息的文件存储机制 <a class="header-anchor" href="#消息的文件存储机制" aria-label="Permalink to &quot;消息的文件存储机制&quot;">​</a></h1><p>​ 前面我们知道了一个 Topic 的多个 partition 在物理磁盘上的保存路径，那么我们再来分析日志的存储方式。通过如下命令找到对应 partition 下的日志内容。</p><div class="language-c vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[root@Darian1 bin]# ls </span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">tmp</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">kafka</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">logs</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">dariantest</span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">2</span><span style="color:#F97583;">/</span></span>
<span class="line"></span>
<span class="line"><span style="color:#FDAEB7;font-style:italic;">00000000000000000000.index</span><span style="color:#E1E4E8;">  </span><span style="color:#FDAEB7;font-style:italic;">00000000000000000000.log</span><span style="color:#E1E4E8;">  </span><span style="color:#FDAEB7;font-style:italic;">00000000000000000000.timeindex</span><span style="color:#E1E4E8;">  leader</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">epoch</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">checkpoint</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[root@Darian1 bin]# ls </span><span style="color:#D73A49;">/</span><span style="color:#24292E;">tmp</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">kafka</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">logs</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">dariantest</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">/</span></span>
<span class="line"></span>
<span class="line"><span style="color:#B31D28;font-style:italic;">00000000000000000000.index</span><span style="color:#24292E;">  </span><span style="color:#B31D28;font-style:italic;">00000000000000000000.log</span><span style="color:#24292E;">  </span><span style="color:#B31D28;font-style:italic;">00000000000000000000.timeindex</span><span style="color:#24292E;">  leader</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">epoch</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">checkpoint</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>​ kafka 是通过分段的方式将 Log 分为多个 LogSegment，LogSegment 是一个逻辑上的概念，一个 LogSegment 对应磁盘上的一个日志文件和一个索引文件，其中日志文件是用来记录消息的。索引文件是用来保存消息的索引。那么这个 LogSegment 是什么呢？</p><h3 id="logsegment" tabindex="-1">LogSegment <a class="header-anchor" href="#logsegment" aria-label="Permalink to &quot;LogSegment&quot;">​</a></h3><p>​ 假如 kafka 以 partition 为最小的存储单位。那么我们可以想象当 kafka producer 不断发送消息，必然会引起 partition 文件的无限扩张。这样对于消息文件的维护以及被消费的消息的清理带来非常大的挑战。所以 kafka 以 segment 为单位又把 partition 进行细分。每个 partition 相当于一个巨型文件被平均分配到多个大小相等的segment 数据文件中（每个 segment 文件中的消息不一定相等），这种特性方便已经被消费的消息的清理，提高磁盘的利用率。</p><div class="language-c vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[root@Darian1 bin]# vim ..</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">config</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">server.properties</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">log.segment.bytes</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">107370</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[root@Darian1 bin]# vim ..</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">config</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">server.properties</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">log.segment.bytes</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">107370</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><ul><li><code>log.segment.bytes</code> = 107370 ( 设置分段大小), 默认是1gb，我们把这个值调小以后，用 <code>producer</code> 去发送分区，可以看到日志分段的效果 <ul><li>抽取其中 3 个分段来进行分析</li></ul></li></ul><p><img src="`+o+`" alt="JavaGuide_Kafka_通信3_segment_分成三段.png"></p><p>​ segment file 由 2 大部分组成，分别为 index file 和 data file，此 2 个文件一一对应，成对出现，后缀&quot;.index&quot;和“.log” 分别表示为 segment 索引文件、数据文件。</p><p>​ segment 文件命名规则：partion 全局的第一个 segment 从 0 开始，后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值进行递增。数值最大为 64 位long 大小，20 位数字字符长度，没有数字用 0 填充。</p><h3 id="查看-segment-文件命名规则" tabindex="-1">查看 segment 文件命名规则 <a class="header-anchor" href="#查看-segment-文件命名规则" aria-label="Permalink to &quot;查看 segment 文件命名规则&quot;">​</a></h3><ul><li><p>通过下面这条命令可以看到 kafka 消息日志的内容</p><div class="language-c vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[root@Darian1 bin]# sh kafka</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">run</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">class.sh kafka.tools.DumpLogSegments </span><span style="color:#F97583;">--</span><span style="color:#E1E4E8;">files </span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">tmp</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">kafka</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">logs</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">dariantest</span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">2</span><span style="color:#F97583;">/</span><span style="color:#FDAEB7;font-style:italic;">00000000000000000000.log</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">--</span><span style="color:#E1E4E8;">print</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">data</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">log</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">输 出 结 果 为 :                                                     </span></span>
<span class="line"><span style="color:#E1E4E8;"> offset: </span><span style="color:#79B8FF;">5376</span><span style="color:#E1E4E8;"> position: </span><span style="color:#79B8FF;">102124</span><span style="color:#E1E4E8;"> CreateTime: </span><span style="color:#79B8FF;">1531477349287</span><span style="color:#E1E4E8;"> isvalid:   </span><span style="color:#79B8FF;">true</span><span style="color:#E1E4E8;"> keysize:      </span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">              valuesize:          </span><span style="color:#79B8FF;">12</span><span style="color:#E1E4E8;">   magic:        </span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;"> compresscodec: NONE producerId: </span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;"> producerEpoch: </span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;"> sequence: </span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;"> isTransactional: </span><span style="color:#79B8FF;">false</span><span style="color:#E1E4E8;"> headerKeys: </span><span style="color:#F97583;">[]</span><span style="color:#E1E4E8;"> payload: message_5376</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[root@Darian1 bin]# sh kafka</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">run</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">class.sh kafka.tools.DumpLogSegments </span><span style="color:#D73A49;">--</span><span style="color:#24292E;">files </span><span style="color:#D73A49;">/</span><span style="color:#24292E;">tmp</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">kafka</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">logs</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">dariantest</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">/</span><span style="color:#B31D28;font-style:italic;">00000000000000000000.log</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">--</span><span style="color:#24292E;">print</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">data</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">log</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">输 出 结 果 为 :                                                     </span></span>
<span class="line"><span style="color:#24292E;"> offset: </span><span style="color:#005CC5;">5376</span><span style="color:#24292E;"> position: </span><span style="color:#005CC5;">102124</span><span style="color:#24292E;"> CreateTime: </span><span style="color:#005CC5;">1531477349287</span><span style="color:#24292E;"> isvalid:   </span><span style="color:#005CC5;">true</span><span style="color:#24292E;"> keysize:      </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">              valuesize:          </span><span style="color:#005CC5;">12</span><span style="color:#24292E;">   magic:        </span><span style="color:#005CC5;">2</span><span style="color:#24292E;"> compresscodec: NONE producerId: </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;"> producerEpoch: </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span><span style="color:#24292E;"> sequence: </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;"> isTransactional: </span><span style="color:#005CC5;">false</span><span style="color:#24292E;"> headerKeys: </span><span style="color:#D73A49;">[]</span><span style="color:#24292E;"> payload: message_5376</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></li></ul><p>​ 第一个 log 文件的最后一个 offset 为:5376,所以下一个segment 的文件命名为: 00000000000000005376.log。对应的 index 为 00000000000000005376.index。</p><h3 id="segment-中-index-和-log-的对应关系" tabindex="-1">segment 中 index 和 log 的对应关系 <a class="header-anchor" href="#segment-中-index-和-log-的对应关系" aria-label="Permalink to &quot;segment 中 index 和 log 的对应关系&quot;">​</a></h3><p>从所有分段中，找一个分段进行分析</p><p>为了提高查找消息的性能，为每一个日志文件添加 2 个索引文件：OffsetIndex 和 TimeIndex，分别对 <code>*.index</code> 以及 <code>*.timeindex</code> , TimeIndex 索引文件格式：它是映射时间戳和相对 offset</p><p>查 看 索 引 内 容 ：</p><div class="language-sh vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[root@Darian1 bin]# sh kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/dariantest-2/00000000000000000000.index -print-data-log</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[root@Darian1 bin]# sh kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/dariantest-2/00000000000000000000.index -print-data-log</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><img src="`+n+`" alt="JavaGuide_Kafka_通信3_segment里边_index_log的对应关系.png"></p><p>​ 如图所示，index 中存储了索引以及物理偏移量。 log 存储了消息的内容。索引文件的元数据执行对应数据文件中message 的物理偏移地址。举个简单的案例来说， 以[4053,80899]为例，在 log 文件中，对应的是第 4053 条记录， 物理偏移量（ position ）为 80899 。 position 是 ByteBuffer 的指针位置。</p><ul><li><p>timeindex 的格式</p><div class="language-c vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">timestamp:</span><span style="color:#79B8FF;">164564</span><span style="color:#E1E4E8;"> offset: </span><span style="color:#79B8FF;">56</span></span>
<span class="line"><span style="color:#E1E4E8;">timestamp:</span><span style="color:#79B8FF;">234234</span><span style="color:#E1E4E8;"> offset: </span><span style="color:#79B8FF;">136</span></span>
<span class="line"><span style="color:#E1E4E8;">timestamp:</span><span style="color:#79B8FF;">432545</span><span style="color:#E1E4E8;"> offset: </span><span style="color:#79B8FF;">635</span></span>
<span class="line"><span style="color:#E1E4E8;">timestamp:</span><span style="color:#79B8FF;">536546</span><span style="color:#E1E4E8;"> offset: </span><span style="color:#79B8FF;">1468</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">timestamp:</span><span style="color:#005CC5;">164564</span><span style="color:#24292E;"> offset: </span><span style="color:#005CC5;">56</span></span>
<span class="line"><span style="color:#24292E;">timestamp:</span><span style="color:#005CC5;">234234</span><span style="color:#24292E;"> offset: </span><span style="color:#005CC5;">136</span></span>
<span class="line"><span style="color:#24292E;">timestamp:</span><span style="color:#005CC5;">432545</span><span style="color:#24292E;"> offset: </span><span style="color:#005CC5;">635</span></span>
<span class="line"><span style="color:#24292E;">timestamp:</span><span style="color:#005CC5;">536546</span><span style="color:#24292E;"> offset: </span><span style="color:#005CC5;">1468</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></li><li><p>index 的格式</p><div class="language-c vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">Indexed offset:</span><span style="color:#79B8FF;">236</span><span style="color:#E1E4E8;"> , found log offset: </span><span style="color:#79B8FF;">326</span></span>
<span class="line"><span style="color:#E1E4E8;">Indexed offset:</span><span style="color:#79B8FF;">345</span><span style="color:#E1E4E8;"> , found log offset: </span><span style="color:#79B8FF;">443</span></span>
<span class="line"><span style="color:#E1E4E8;">Indexed offset:</span><span style="color:#79B8FF;">546</span><span style="color:#E1E4E8;"> , found log offset: </span><span style="color:#79B8FF;">567</span></span>
<span class="line"><span style="color:#E1E4E8;">Indexed offset:</span><span style="color:#79B8FF;">765</span><span style="color:#E1E4E8;"> , found log offset: </span><span style="color:#79B8FF;">676</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">Indexed offset:</span><span style="color:#005CC5;">236</span><span style="color:#24292E;"> , found log offset: </span><span style="color:#005CC5;">326</span></span>
<span class="line"><span style="color:#24292E;">Indexed offset:</span><span style="color:#005CC5;">345</span><span style="color:#24292E;"> , found log offset: </span><span style="color:#005CC5;">443</span></span>
<span class="line"><span style="color:#24292E;">Indexed offset:</span><span style="color:#005CC5;">546</span><span style="color:#24292E;"> , found log offset: </span><span style="color:#005CC5;">567</span></span>
<span class="line"><span style="color:#24292E;">Indexed offset:</span><span style="color:#005CC5;">765</span><span style="color:#24292E;"> , found log offset: </span><span style="color:#005CC5;">676</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></li></ul><h3 id="在-partition-中如何通过-offset-查找-message" tabindex="-1">在 partition 中如何通过 offset 查找 message <a class="header-anchor" href="#在-partition-中如何通过-offset-查找-message" aria-label="Permalink to &quot;在 partition 中如何通过 offset 查找 message&quot;">​</a></h3><p>查找的算法是</p><ol><li><p>根据 offset 的值，查找 segment 段中的 index 索引文件。由于索引文件命名是以上一个文件的最后一个offset 进行命名的，所以，使用二分查找算法能够根据offset 快速定位到指定的索引文件。</p></li><li><p>找到索引文件后，根据 offset 进行定位，找到索引文件中的符合范围的索引。（kafka 采用稀疏索引的方式来提高查找性能）</p></li><li><p>得到 position 以后，再到对应的 log 文件中，从 position 处开始查找 offset 对应的消息，将每条消息的 offset 与目标 offset 进行比较，直到找到消息</p></li></ol><p>​ 比如说，我们要查找 offset=2490 这条消息，那么先找到 <code>00000000000000000000.index</code> , 然后找到 <code>[2487,49111]</code> 这个索引，再到 log 文件中，根据 49111 这个 position 开始查找，比较每条消息的 offset 是否大于等于 2490。最后查找到对应的消息以后返回。</p><h3 id="log-文件的消息内容分析" tabindex="-1">Log 文件的消息内容分析 <a class="header-anchor" href="#log-文件的消息内容分析" aria-label="Permalink to &quot;Log 文件的消息内容分析&quot;">​</a></h3><p>​ 前面我们通过 kafka 提供的命令，可以查看二进制的日志文件信息，一条消息，会包含很多的字段。</p><div class="language-c vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">offset: </span><span style="color:#79B8FF;">5371</span><span style="color:#E1E4E8;"> position: </span><span style="color:#79B8FF;">102124</span><span style="color:#E1E4E8;"> CreateTime: </span><span style="color:#79B8FF;">1531477349286</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">isvalid:   </span><span style="color:#79B8FF;">true</span><span style="color:#E1E4E8;">    keysize:    </span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">    valuesize:   </span><span style="color:#79B8FF;">12</span><span style="color:#E1E4E8;">              magic:               </span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;"> compresscodec: NONE producerId: </span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;"> producerEpoch: </span><span style="color:#F97583;">-</span></span>
<span class="line"></span>
<span class="line"><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">   sequence:   </span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">   isTransactional:  </span><span style="color:#79B8FF;">false</span><span style="color:#E1E4E8;">    headerKeys:     </span><span style="color:#F97583;">[]</span><span style="color:#E1E4E8;"> payload: message_5371</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">offset: </span><span style="color:#005CC5;">5371</span><span style="color:#24292E;"> position: </span><span style="color:#005CC5;">102124</span><span style="color:#24292E;"> CreateTime: </span><span style="color:#005CC5;">1531477349286</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">isvalid:   </span><span style="color:#005CC5;">true</span><span style="color:#24292E;">    keysize:    </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">    valuesize:   </span><span style="color:#005CC5;">12</span><span style="color:#24292E;">              magic:               </span><span style="color:#005CC5;">2</span><span style="color:#24292E;"> compresscodec: NONE producerId: </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;"> producerEpoch: </span><span style="color:#D73A49;">-</span></span>
<span class="line"></span>
<span class="line"><span style="color:#005CC5;">1</span><span style="color:#24292E;">   sequence:   </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">   isTransactional:  </span><span style="color:#005CC5;">false</span><span style="color:#24292E;">    headerKeys:     </span><span style="color:#D73A49;">[]</span><span style="color:#24292E;"> payload: message_5371</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>offset 和 position 这两个前面已经讲过了、createTime 表示创建时间、keysize 和 valuesize 表示 key 和 value 的大小、 compresscodec 表示压缩编码、payload:表示消息的具体内容</p><h2 id="日志的清除策略以及压缩策略" tabindex="-1">日志的清除策略以及压缩策略 <a class="header-anchor" href="#日志的清除策略以及压缩策略" aria-label="Permalink to &quot;日志的清除策略以及压缩策略&quot;">​</a></h2><h3 id="日志清除策略" tabindex="-1">日志清除策略 <a class="header-anchor" href="#日志清除策略" aria-label="Permalink to &quot;日志清除策略&quot;">​</a></h3><p>​ 前面提到过，日志的分段存储，一方面能够减少单个文件内容的大小，另一方面，方便 kafka 进行日志清理。日志的清理策略有两种。</p><ol><li><p>根据消息的保留时间，当消息在 kafka 中保存的时间超过了指定的时间，就会触发清理过程</p></li><li><p>根据 topic 存储的数据大小，当 topic 所占的日志文件大小大于一定的阈值，则可以开始删除最旧的消息。kafka 会启动一个后台线程，定期检查是否存在可以删除的消息。</p></li></ol><div class="language-c vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[root@Darian1 bin]# vim ..</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">config</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">server.properties</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[root@Darian1 bin]# vim ..</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">config</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">server.properties</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>​ 通过 <code>log.retention.bytes</code> 和 <code>log.retention.hours</code> 这两个参数来设置，当其中任意一个达到要求，都会执行删除。 默认的保留时间是：7 天。</p><h3 id="日志压缩策略" tabindex="-1">日志压缩策略 <a class="header-anchor" href="#日志压缩策略" aria-label="Permalink to &quot;日志压缩策略&quot;">​</a></h3><p>​ Kafka 还提供了 “ 日志压缩（ <code>Log Compaction</code> ）”功能，通 过这个功能可以有效地减少日志文件的大小，缓解磁盘紧张的情况，在很多实际场景中，消息的 key 和 value 的值之间的对应关系是不断变化的，就像数据库中的数据会不断被修改一样，消费者只关心 key 对应的最新的 value。因此，我们可以开启 kafka 的日志压缩功能，服务端会在后台启动 Cleaner 线程池，定期将相同的 key 进行合并， 只保留最新的 value 值。日志的压缩原理是。</p><p>​ 当你的消息有很多的时候，前面有已经变化过的 Key 。</p><ul><li>key = 1 <ul><li>value = 2 变成 3</li></ul></li></ul><p>​ 最后把相同的可以取出来最新的数据，生成一个 swap 一样的临时文件。去做一个压缩写入，再去写入替换为正式的 <code>index</code> 文件。这就是一个压缩的过程。</p><p>​ 针对每一个分段的日志都会采取压缩的机制。最后，相同的 key 只存在最大的 offset 。</p><p><img src="`+p+'" alt="JavaGuide_Kafka_通信3_日志压缩策略.png"></p><h1 id="partition-的高可用副本机制" tabindex="-1">partition 的高可用副本机制 <a class="header-anchor" href="#partition-的高可用副本机制" aria-label="Permalink to &quot;partition 的高可用副本机制&quot;">​</a></h1><p>​ 我们已经知道 Kafka 的每个topic 都可以分为多个 Partition ， 并且多个 partition 会均匀分布在集群的各个节点下。虽然 这种方式能够有效地对数据进行分片，但是对于每 partition 来说，都是单点的，当其中一个 partition 不可用的时候，那么这部分消息就没办法消费。所以 kafka 为了提高 partition 的可靠性而提供了副本的概念（Replica），通过副本机制来实现冗余备份。</p><p>​ 每个分区可以有多个副本，并且在副本集合中会存在一个 Leader 的副本。所有的读写请求都是由 leader 副本来进行处理。剩余的其他副本都作为 Follower 副本。Follower 副本会从 Leader 副本同步消息日志。这个有点类似 zookeeper 中 Leader 和 Follower 的概念，但是具体的时间方式还是有比较大的差异。所以我们可以认为，副本集会存在一主多从的关系。</p><p>​ 一般情况下，同一个分区的多个副本会被均匀分配到集群中的不同 broker 上。当 leader 副本所在的 Broker 出现故障后，可以重新选举新的 leader 副本继续对外提供服务。通过这样的副本机制来提高 kafka 集群的可用性。</p><h2 id="副本分配算法" tabindex="-1">副本分配算法 <a class="header-anchor" href="#副本分配算法" aria-label="Permalink to &quot;副本分配算法&quot;">​</a></h2><ul><li><p>将所有 N Broker 和待分配的 i 个 Partition 排序</p></li><li><p>将第 i 个 Partition 分配到第( i mod n ) 个 Broker 上</p></li><li><p>将第 i 个 Partition 的第 j 个副本分配到第 ( ( i + j ) mod n ) 个Broker 上</p></li></ul><h2 id="创建一个带副本机制的-topic" tabindex="-1">创建一个带副本机制的 topic <a class="header-anchor" href="#创建一个带副本机制的-topic" aria-label="Permalink to &quot;创建一个带副本机制的 topic&quot;">​</a></h2><p>通过下面的命令去创建带 2 个副本的 Topic</p><div class="language-sh vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[root@Darian3 bin]# sh ./kafka-topics.sh --create --zookeeper 192.168.11.156:2181 --replication-factor 2 --partitions 3 -- topic secondTopic</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[root@Darian3 bin]# sh ./kafka-topics.sh --create --zookeeper 192.168.11.156:2181 --replication-factor 2 --partitions 3 -- topic secondTopic</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>然后我们可以在/tmp/kafka-log 路径下看到对应 topic 的副本信息了。我们通过一个图形的方式来表达。</p><ul><li>secondTopic 这个 topic 有 3 个分区，分别对应的 3 个副本</li></ul><p><img src="'+t+`" alt="JavaGuide_Kafka_通信3_一个Topic_三个分区_三个副本.png"></p><p>如何知道各个分区中对应的 leader 是谁呢？</p><p>在 zookeeper 服务器上，通过如下命令去获取对应分区的信息，比如下面这个是获取 secondTopic 第 1 个分区的状态信息。</p><div class="language-c vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[zk: localhost:</span><span style="color:#79B8FF;">2181</span><span style="color:#E1E4E8;">(CONNECTED) </span><span style="color:#79B8FF;">14</span><span style="color:#E1E4E8;">] get </span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">brokers</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">topics</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">secondTopic</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">partitions</span><span style="color:#F97583;">/</span><span style="color:#79B8FF;">1</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">state</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">{</span><span style="color:#9ECBFF;">&quot;controller_epoch&quot;</span><span style="color:#E1E4E8;">:</span><span style="color:#79B8FF;">12</span><span style="color:#E1E4E8;">,</span><span style="color:#9ECBFF;">&quot;leader&quot;</span><span style="color:#E1E4E8;">:</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">,</span><span style="color:#9ECBFF;">&quot;version&quot;</span><span style="color:#E1E4E8;">:</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">,</span><span style="color:#9ECBFF;">&quot;leader_ep och&quot;</span><span style="color:#E1E4E8;">:</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">,</span><span style="color:#9ECBFF;">&quot;isr&quot;</span><span style="color:#E1E4E8;">:[</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">,</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">]}</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[zk: localhost:</span><span style="color:#005CC5;">2181</span><span style="color:#24292E;">(CONNECTED) </span><span style="color:#005CC5;">14</span><span style="color:#24292E;">] get </span><span style="color:#D73A49;">/</span><span style="color:#24292E;">brokers</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">topics</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">secondTopic</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">partitions</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">1</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">state</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">{</span><span style="color:#032F62;">&quot;controller_epoch&quot;</span><span style="color:#24292E;">:</span><span style="color:#005CC5;">12</span><span style="color:#24292E;">,</span><span style="color:#032F62;">&quot;leader&quot;</span><span style="color:#24292E;">:</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#032F62;">&quot;version&quot;</span><span style="color:#24292E;">:</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#032F62;">&quot;leader_ep och&quot;</span><span style="color:#24292E;">:</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#032F62;">&quot;isr&quot;</span><span style="color:#24292E;">:[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>​ leader 表示当前分区的 leader 是那个 broker-id。如下图中。绿色线条的表示该分区中的 leader 节点。其他节点就为 follower。</p><p><img src="`+r+'" alt="JavaGuide_Kafka_通信3_一个Topic_三个分区_三个副本_leader_follower.png"></p><p>​ Kafka 提供了数据复制算法保证，如果 leader 发生故障或挂掉，一个新 leader 被选举并被接受客户端的消息成功写入。Kafka 确保从同步副本列表中选举一个副本为 leader ；</p><p>​ leader 负责维护和跟踪 ISR ( in-Sync replicas ， 副本同步队列 ) 中所有 follower 之后的状态。当 producer 发送一条消息到 broker 后，leader 写入消息并复制到所有 follower。消息提交之后才被成功复制到所有的同步副本。</p><ul><li>既然有副本机制，就一定涉及数据同步的概念，那接下来分析下数据是如何同步的？</li></ul><p>​ 需要注意的是， 大家不要把 zookeeper 的 leader 和follower 的同步机制和 kafka 副本的同步机制搞混了。虽然从思想层面来说是一样的，但是原理层面的实现是完全不同的。</p><p>​ Lollowers 副本集必须要和 Leader 副本的数据在阈值范围内保持一致。当其中一个副本和 Leader 副本数据存在比较大的偏差的话，他就会被踢出去。 “我们项目组都是精英，如果你是一个菜鸡，我就要把你踢出去。”</p><h2 id="kafka-副本机制中的几个概念" tabindex="-1">kafka 副本机制中的几个概念 <a class="header-anchor" href="#kafka-副本机制中的几个概念" aria-label="Permalink to &quot;kafka 副本机制中的几个概念&quot;">​</a></h2><p>​ Kafka 分区下有可能有很多个副本(replica)用于实现冗余， 从而进一步实现高可用。副本根据角色的不同可分为 3 类：</p><ul><li>Leader 副本：响应 clients 端读、写请求的副本</li><li>Follower 副本：被动地备份 leader 副本中的数据，不能响应 clients 端读写请求 。</li><li>ISR 副本：包含了 leader 副本和所有与 leader 副本保持同步的 follower 副本——如何判定是否与 leader 同步后面会提到每个 Kafka 副本对象都有两个重要的属性：LEO 和 HW。注意是所有的副本，而不只是 leader 副本。</li></ul><h5 id="leo" tabindex="-1">LEO： <a class="header-anchor" href="#leo" aria-label="Permalink to &quot;LEO：&quot;">​</a></h5><ul><li>即日志末端位移(log end offset)，记录了该副本底层日志(log)中下一条消息的位移值。注意是下一条消息！也就是说，如果 LEO=10，那么表示该副本保存了 10 条消息，位移值范围是[0, 9]。另外，leader LEO 和 follower LEO 的更新是有区别的。我们后面会详细说。</li></ul><h5 id="hw" tabindex="-1">HW： <a class="header-anchor" href="#hw" aria-label="Permalink to &quot;HW：&quot;">​</a></h5><ul><li>即上面提到的水位值。对于同一个副本对象而言，其 HW 值不会大于 LEO 值。小于等于 HW 值的所有消息都被认为是“已备份”的（replicated）<code>（都能够被消费者去消费）</code>。同理，leader 副本和follower 副本的 HW 更新是有区别的。</li></ul><h2 id="副本协同机制" tabindex="-1">副本协同机制 <a class="header-anchor" href="#副本协同机制" aria-label="Permalink to &quot;副本协同机制&quot;">​</a></h2><p>​ 刚刚提到了，消息的读写操作都只会由 leader 节点来接收和处理。follower 副本只负责同步数据以及当 leader 副本所在的 broker 挂了以后，会从 follower 副本中选取新的leader。</p><p><img src="'+c+'" alt="JavaGuide_Kafka_通信3_副本协同机制.png"></p><p>​ 写请求首先由 Leader 副本处理，之后 follower 副本会从leader 上拉取写入的消息，这个过程会有一定的延迟，导致 follower 副本中保存的消息略少于 leader 副本，但是只要没有超出阈值都可以容忍。但是如果一个 follower 副本出现异常，比如宕机、网络断开等原因长时间没有同步到消息，那这个时候，leader 就会把它踢出去。kafka 通过 ISR 集合来维护一个分区副本信息。</p><h2 id="isr" tabindex="-1">ISR <a class="header-anchor" href="#isr" aria-label="Permalink to &quot;ISR&quot;">​</a></h2><p>​ ISR 表示目前“可用且消息量与 leader 相差不多的副本集合， 这是整个副本集合的一个子集”。怎么去理解可用和相差不多这两个词呢？具体来说，ISR 集合中的副本必须满足两个条件。</p><ol><li><p>副本所在节点必须维持着与 zookeeper 的连接</p></li><li><p>Follower 副本最后一条消息的 offset 与 Leader 副本的最后一条消息的 offset 之间的差值不能超过指定的阈值(replica.lag.time.max.ms)</p><p><code>replica.lag.time.max.ms</code>：如果该 follower 在此时间间隔内一直没有追上过 leader 的所有消息，则该 follower 就会被剔除 isr 列表</p></li></ol><ul><li>ISR 数 据 保 存 在 Zookeeper 的</li></ul><p>/brokers/topics/&lt;topic&gt;/partitions/&lt;partitionId&gt;/state 节点中</p><h2 id="hw-leo" tabindex="-1">HW&amp;LEO <a class="header-anchor" href="#hw-leo" aria-label="Permalink to &quot;HW&amp;LEO&quot;">​</a></h2><p>​ 关于 follower 副本同步的过程中，还有两个关键的概念，HW(HighWatermark)和 LEO(Log End Offset). 这两个参数跟 ISR 集合紧密关联。HW 标记了一个特殊的 offset，当消费者处理消息的时候，只能拉取到 HW 之前的消息，HW 之后的消息对消费者来说是不可见的。也就是说， 取partition 对应 ISR 中最小的 LEO 作为 HW，consumer 最多只能消费到 HW 所在的位置。每个 replica 都有 HW，leader 和 follower 各自维护更新自己的 HW 的状态。一条消息只有被 ISR 里的所有 Follower 都从 Leader 复制过去才会被认为已提交。这样就避免了部分数据被写进了Leader，还没来得及被任何 Follower 复制就宕机了，从而造成数据丢失（Consumer 无法消费这些数据）。而对于Producer 而言，它可以选择是否等待消息 commit，这可以通过 acks 来设置。这种机制确保了只要 ISR 有一个或以上的 Follower，一条被 commit 的消息就不会丢失。</p><h2 id="数据的同步过程" tabindex="-1">数据的同步过程 <a class="header-anchor" href="#数据的同步过程" aria-label="Permalink to &quot;数据的同步过程&quot;">​</a></h2><p>​ 了解了副本的协同过程以后，还有一个最重要的机制，就是数据的同步过程。它需要解决。</p><ol><li><p>怎么传播消息</p></li><li><p>在向消息发送端返回 ack 之前需要保证多少个 Replica已经接收到这个消息</p></li></ol><p>数据的处理过程是</p><p>​ Producer 在 发 布 消 息 到 某 个 Partition 时 ， 先 通 过ZooKeeper 找 到 该 Partition 的 Leader 【 get/brokers/topics/&lt;topic&gt;/partitions/2/state】，然后无论该Topic 的 Replication Factor 为多少（也即该 Partition 有多少个 Replica），Producer 只将该消息发送到该 Partition 的Leader。Leader 会将该消息写入其本地Log。每个Follower 都从 Leader pull 数据。这种方式上，Follower 存储的数据顺序与 Leader 保持一致。Follower 在收到该消息并写入其Log 后，向 Leader 发送 ACK。一旦 Leader 收到了 ISR 中的所有 Replica 的 ACK，该消息就被认为已经 commit 了，Leader 将增加 HW ( HighWatermark ) 并且向 Producer 发送 ACK。</p><h3 id="初始状态" tabindex="-1">初始状态 <a class="header-anchor" href="#初始状态" aria-label="Permalink to &quot;初始状态&quot;">​</a></h3><p>​ 初始状态下，leader 和 follower 的 HW 和 LEO 都是 0，leader 副本会保存 remote LEO，表示所有 follower LEO， 也会被初始化为 0，这个时候，producer 没有发送消息。</p><p>​ follower 会不断地给 leader 发送 FETCH 请求，但是因为没有数据，这个请求会被 leader 寄存。当在指定的时间之后会强制完成请求。这个时间配置是(replica.fetch.wait.max.ms)。如果在指定时间内 producer 有消息发送过来，那么 kafka 会唤醒 fetch 请求，让 leader 继续处理。</p><p><img src="'+i+'" alt="JavaGuide_Kafka_通信3_Leader_Follower初始状态.png"></p><p>​ 这里会分两种情况，第一种是 leader 处理完 producer 请求之后，follower 发送一个 fetch 请求过来。第二种是follower 阻塞在 leader 指定时间之内，leader 副本收到producer 的请求。这两种情况下处理方式是不一样的。先来看第一种情况。</p><h2 id="follower-的-fetch-请求是当-leader-处理消息以后执行的" tabindex="-1">follower 的 fetch 请求是当 leader 处理消息以后执行的 <a class="header-anchor" href="#follower-的-fetch-请求是当-leader-处理消息以后执行的" aria-label="Permalink to &quot;follower 的 fetch 请求是当 leader 处理消息以后执行的&quot;">​</a></h2><h3 id="生产者发送一条消息" tabindex="-1">生产者发送一条消息 <a class="header-anchor" href="#生产者发送一条消息" aria-label="Permalink to &quot;生产者发送一条消息&quot;">​</a></h3><ul><li>leader 处理完 producer 请求之后，follower 发送一个fetch 请求过来 。状态图如下</li></ul><p><img src="'+d+'" alt="JavaGuide_Kafka_通信3_生产者发送一条消息.png"></p><p>leader 副本收到请求以后，会做几件事情</p><ol><li><p>把消息追加到 log 文件，同时更新 leader 副本的 LEO</p></li><li><p>尝试更新 leader HW 值。这个时候由于 follower 副本还没有发送 fetch 请求，那么 leader 的 remote LEO 仍然是 0。leader 会比较自己的 LEO 以及 remote LEO 的值发现最小值是 0，与 HW 的值相同，所以不会更新 HW。</p></li></ol><h3 id="follower-fetch-消息" tabindex="-1">Follower fetch 消息 <a class="header-anchor" href="#follower-fetch-消息" aria-label="Permalink to &quot;Follower fetch 消息&quot;">​</a></h3><p><img src="'+y+'" alt="JavaGuide_Kafka_通信3_Follower_Fetch消息.png"></p><p>follower 发送 fetch 请求，leader 副本的处理逻辑是：</p><ol><li><p>读取 log 数据、更新 remote LEO=0(follower 还没有写入这条消息，这个值是根据 follower 的 fetch 请求中的offset 来确定的)</p></li><li><p>尝试更新 HW，因为这个时候 LEO 和 remoteLEO 还是不一致，所以仍然是 HW=0</p></li><li><p>把消息内容和当前分区的 HW 值发送给 follower 副本</p></li></ol><p>follower 副本收到 response 以后</p><ol><li><p>将消息写入到本地 log，同时更新 follower 的 LEO</p></li><li><p>更新 follower HW，本地的 LEO 和 leader 返回的 HW进行比较取小的值，所以仍然是 0</p></li></ol><p>第一次交互结束以后，HW 仍然还是 0，这个值会在下一次 follower 发起 fetch 请求时被更新</p><p><img src="'+E+'" alt="JavaGuide_Kafka_通信3_Follower_副本收到消息.png"></p><p>follower 发起第二次 fetch 请求，leader 收到请求以后</p><ol><li><p>读取 log 数据</p></li><li><p>更新 remote LEO=1， 因为这次 fetch 携带的 offset 是 1.</p></li><li><p>更新当前分区的 HW，这个时候 leader LEO 和 remote LEO 都是 1，所以 HW 的值也更新为 1</p></li><li><p>把数据和当前分区的 HW 值返回给 follower 副本，这个时候如果没有数据，则返回为空</p></li></ol><p>follower 副本收到 response 以后</p><ol><li><p>如果有数据则写本地日志，并且更新 LEO</p></li><li><p>更新 follower 的 HW 值</p></li></ol><p>到目前为止，数据的同步就完成了，意味着消费端能够消费 offset=0 这条消息。</p><p><img src="'+f+'" alt="JavaGuide_Kafka_通信3_数据更新完成.png"></p><h2 id="follower-的-fetch-请求是直接从阻塞过程中触发" tabindex="-1">follower 的 fetch 请求是直接从阻塞过程中触发 <a class="header-anchor" href="#follower-的-fetch-请求是直接从阻塞过程中触发" aria-label="Permalink to &quot;follower 的 fetch 请求是直接从阻塞过程中触发&quot;">​</a></h2><p>​ 前面说过，由于 leader 副本暂时没有数据过来，所以follower 的 fetch 会被阻塞，直到等待超时或者 leader 接收到新的数据。当 leader 收到请求以后会唤醒处于阻塞的 fetch 请求。处理过程基本上和前面说的一致。</p><ol><li><p>leader 将消息写入本地日志，更新 Leader 的 LEO</p></li><li><p>唤醒 follower 的 fetch 请求</p></li><li><p>更新 HW</p></li></ol><p>​ kafka 使用 HW 和 LEO 的方式来实现副本数据的同步，本身是一个好的设计，但是在这个地方会存在一个数据丢失的问题，当然这个丢失只出现在特定的背景下。我们回想一下，HW 的值是在新的一轮 FETCH 中才会被更新。我们分析下这个过程为什么会出现数据丢失。</p><h2 id="数据丢失的问题" tabindex="-1">数据丢失的问题 <a class="header-anchor" href="#数据丢失的问题" aria-label="Permalink to &quot;数据丢失的问题&quot;">​</a></h2><p>​ 前提：<code>min.insync.replicas=1</code> 的时候。-&gt;设定 ISR 中的最小副本数是多少，默认值为 1, 当且仅当 acks 参数设置为-1（表示需要所有副本确认）时，此参数才生效。表达的含义是，至少需要多少个副本同步才能表示消息是提交的。</p><p>​ 所以，<code>min.insync.replicas=1</code> 的时候写入消息被写入 leader 端 log 即被认为是“已提交”，而延迟一轮 FETCHRPC 更新 HW 值的设计使得 follower HW 值是异步延迟更新的，倘若在这个过程中leader 发生变更， 那么成为新 leader 的 follower 的 HW 值就有可能是过期的，使得 clients 端认为是成功提交的消息被删除。</p><p><img src="'+u+'" alt="JavaGuide_Kafka_通信3_数据丢失问题.png"></p><h2 id="数据丢失的解决方案" tabindex="-1">数据丢失的解决方案 <a class="header-anchor" href="#数据丢失的解决方案" aria-label="Permalink to &quot;数据丢失的解决方案&quot;">​</a></h2><p>​ 在 kafka0.11.0.0 版本以后，提供了一个新的解决方案，使用 leader epoch 来解决这个问题，leader epoch 实际上是一对之(epoch,offset), epoch 表示 leader 的版本号，从 0 开始，当 leader 变更过 1 次时 epoch 就会+1，而 offset 则对应于该 epoch 版本的 leader 写入第一条消息的位移。比如说。</p><p>(0,0) ; (1,50); 表示第一个 leader 从 offset=0 开始写消息， 一共写了 50 条，第二个 leader 版本号是 1，从 50 条处开始写消息。这个信息保存在对应分区的本地磁盘文件中，文件名为 ：</p><div class="language-c vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">tml</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">kafka</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">log</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">topic</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">leader</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">epoch</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;"> checkpoint</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">/</span><span style="color:#24292E;">tml</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">kafka</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">log</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">topic</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">leader</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">epoch</span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> checkpoint</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>leader broker 中会保存这样的一个缓存，并定期地写入到一个 checkpoint 文件中。</p><p>当 leader 写 log 时它会尝试更新整个缓存——如果这个leader 首次写消息，则会在缓存中增加一个条目；否则就不做更新。而每次副本重新成为 leader 时会查询这部分缓存，获取出对应 leader 版本的 offset。</p><p><img src="'+h+'" alt="JavaGuide_Kafka_通信3_数据丢失问题解决方案.png"></p><h2 id="如何处理所有的-replica-不工作的情况" tabindex="-1">如何处理所有的 Replica 不工作的情况 <a class="header-anchor" href="#如何处理所有的-replica-不工作的情况" aria-label="Permalink to &quot;如何处理所有的 Replica 不工作的情况&quot;">​</a></h2><p>​ 在 ISR 中至少有一个 follower 时，Kafka 可以确保已经 commit 的数据不丢失。但如果某个 Partition 的所有 Replica 都宕机了，就无法保证数据不丢失。</p><ol><li><p>等待 ISR 中的任何一个 Replica “ 活”过来，并且选它作为 Leader</p></li><li><p>选择第一个“活”过来的 Replica（不一定是 ISR 中的）作为 Leader</p></li></ol><p>​ 这就需要在可用性和一致性当中作出一个简单的折中。</p><p>​ 如果一定要等待 ISR 中的 Replica “ 活 ” 过来，那不可用的时间就可能会相对较长。而且如果 ISR 中的所有 Replica 都无法“活”过来了，或者数据都丢失了，这个 Partition 将永远不可用。</p><p>​ 选择第一个“ 活” 过来的 Replica 作为 Leader， 而这个Replica 不是 ISR 中的 Replica，那即使它并不保证已经包含了所有已 commit 的消息，它也会成为 Leader 而作为consumer 的数据源（前文有说明，所有读写都由 Leader 完成）。在我们课堂讲的版本中，使用的是第一种策略。</p><p>默认的 kafka 是 500 ms 检查一次？</p><h3 id="isr-的设计原理" tabindex="-1">ISR 的设计原理 <a class="header-anchor" href="#isr-的设计原理" aria-label="Permalink to &quot;ISR 的设计原理&quot;">​</a></h3><p>​ 在所有的分布式存储中，冗余备份是一种常见的设计方式，而常用的模式有同步复制和异步复制，按照 kafka 这个副本模型来说</p><p>​ 如果采用同步复制，那么需要要求所有能工作的 Follower 副本都复制完，这条消息才会被认为提交成功，一旦有一个follower 副本出现故障，就会导致 HW 无法完成递增，消息就无法提交，消费者就获取不到消息。这种情况下，故障的Follower 副本会拖慢整个系统的性能，设置导致系统不可用如果采用异步复制，leader 副本收到生产者推送的消息后，就认为此消息提交成功。Follower 副本则异步从 leader 副本同步数据。这种设计虽然避免了同步复制的问题，但是假设所有follower 副本的同步速度都比较慢，那他们保存的消息量远远落后于 leader 副本。而此时 leader 副本所在的 broker 突然宕机，则会重新选举新的 leader 副本，而新的 leader 副本中没有原来 leader 副本的消息。这就出现了消息的丢失。</p><p>​ kafka 权衡了同步和异步的两种策略，采用 ISR 集合，巧妙解决了两种方案的缺陷。当 follower 副本延迟过高，leader 副本则会把该 follower 副本提出 ISR 集合，消息依然可以快速提交。当 leader 副本所在的 broker 突然宕机，会优先将 ISR 集合中follower 副本选举为 leader，新 leader 副本包含了 HW 之前的全部消息，这样就避免了消息的丢失。</p><h1 id="qa" tabindex="-1">QA： <a class="header-anchor" href="#qa" aria-label="Permalink to &quot;QA：&quot;">​</a></h1><ol><li>key 的传递：</li></ol><p><img src="'+m+`" alt="JavaGuide_Kafka_通信3_Kafka发送数据.png"></p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">public</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">ProducerRecord</span><span style="color:#E1E4E8;">(String topic, K key, V value) {</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#79B8FF;">this</span><span style="color:#E1E4E8;">(topic, (Integer)</span><span style="color:#79B8FF;">null</span><span style="color:#E1E4E8;">, (Long)</span><span style="color:#79B8FF;">null</span><span style="color:#E1E4E8;">, key, value, (Iterable)</span><span style="color:#79B8FF;">null</span><span style="color:#E1E4E8;">);</span></span>
<span class="line"><span style="color:#E1E4E8;">}</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">public</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">ProducerRecord</span><span style="color:#24292E;">(String topic, K key, V value) {</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#005CC5;">this</span><span style="color:#24292E;">(topic, (Integer)</span><span style="color:#005CC5;">null</span><span style="color:#24292E;">, (Long)</span><span style="color:#005CC5;">null</span><span style="color:#24292E;">, key, value, (Iterable)</span><span style="color:#005CC5;">null</span><span style="color:#24292E;">);</span></span>
<span class="line"><span style="color:#24292E;">}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><ol start="2"><li>分区应该设置多少合适？</li></ol><p>答：根据我们的吞吐量去设置。分区数不是越多越好，希望达到的吞吐量。</p><ul><li>采用操作系统的页缓存来缓存数据</li><li>日志采用顺序写入以及零拷贝提升 IO 性能</li><li>partition 的水平分区的概念，能够把一个 topic 拆分到多个分区。</li><li>发送端和消费端都可以采用并行的方式来消费分区中的信息。</li></ul><p>​ 设置 50000 个分区的时候。批量发送 <code>batch.size</code> , <code>linger.ms</code> （ 针对同一个 patitition 而言 ）</p><p>消息缓存在内存里，可能会导致内存占用过高。</p><p>​ 50000 个分区 50000个消费者，能够达到最大的性能。多线程，一个消费者可以设置 10 个线程去消费消息，意味着我们要设置 5000 个消费者线程。</p><ul><li><p>怎么去分配 consumer 的消费能力。没有消费能力，白搭。</p></li><li><p>文件句柄。我们每一个分区都会存在 logsegment -&gt; index / log 文件</p></li><li><p>分区越多，打开的文件句柄就需要越多。</p></li><li><p>副本，（有的场景不需要副本）50000 个分区落到 10 个 Broker 上。每个 broker 有 5000 个分区。5000 个分区，需要选举 5000 个 Leader分区 。</p></li><li><p>硬件资源</p></li><li><p>消息大小</p></li><li><p>目标吞吐量</p></li></ul><p>压测一个 Topic 一个 Partititon 单机的情况下是怎么样的。压测得到 TPS 的值。</p><p>消息大小：取的是峰值。</p><p>假如说 TPS 是 10M/s ，意味着 我们希望 100M/s 的时候， 10 个分区，10 个消费者就好了。</p>`,157),b=[k];function F(v,_,C,w,q,L){return s(),e("div",null,b)}const x=a(g,[["render",F]]);export{D as __pageData,x as default};
